# SarcasmDetectorModels
This project evaluates multiple transformer models for sarcasm detection across mixed datasets. RoBERTa-base offers the best balance of accuracy and stability. Results show data quality matters more than size, and models still struggle with context-dependent sarcasm.
